<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Room Mode - Sign Language & Speech Translator </title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/holistic/holistic.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.socket.io/4.7.5/socket.io.min.js"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            primary: '#3B82F6',
            secondary: '#60A5FA'
          }
        }
      }
    }
  </script>
  <style>
    .hidden { display: none; }
    #video { border: 2px solid #000; transform: scaleX(-1); }
    #canvas { position: absolute; top: 100px; left: 50%; transform: translateX(-50%) scaleX(-1); }
    #audioCanvas { display: none; }
    .disabled { opacity: 0.5; pointer-events: none; }
  </style>
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
  <div class="max-w-4xl mx-auto p-6 space-y-8">
    <header class="text-center">
      <h1 class="text-4xl font-bold text-primary">Room Mode</h1>
      <p class="text-gray-500 mt-2">Create or join a room for real-time translation</p>
    </header>

    <div class="space-y-4">
      <div class="flex justify-center space-x-4">
        <button id="selectSignBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Select Sign Translation</button>
        <button id="selectSpeechBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Select Speech Translation</button>
      </div>

      <div>
        <button id="createRoomBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Create Room</button>
        <div class="mt-2">
          <input type="text" id="joinRoomInput" placeholder="Enter Room ID to Join" class="border p-2 rounded w-64">
          <button id="joinRoomBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary ml-2 transition">Join Room</button>
        </div>
        <div id="currentRoom" class="mt-2 text-lg text-gray-700"></div>
      </div>

      <div id="signSection" class="section hidden">
        <h2 class="text-2xl font-semibold text-primary mb-4">Sign Language Translation</h2>
        <video id="video" width="480" height="360" autoplay></video>
        <canvas id="canvas" width="480" height="360"></canvas>
        <br>
        <button id="startSignBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary mt-2">Start</button>
        <button id="stopSignBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Stop</button>
        <button id="submitSignBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Translate</button>
        <div id="progress-sign" class="mt-2 text-gray-600">Progress: 0%</div>
        <div id="output-sign" class="mt-2 text-xl"></div>
        <div id="probabilities-sign" class="mt-2 text-gray-600"></div>
      </div>

      <div id="speechSection" class="section hidden">
        <h2 class="text-2xl font-semibold text-primary mb-4">Speech Translation</h2>
        <canvas id="audioCanvas" width="480" height="100"></canvas>
        <br>
        <button id="startSpeechBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary mt-2">Start</button>
        <button id="stopSpeechBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Stop</button>
        <button id="submitSpeechBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Translate</button>
        <div id="progress-speech" class="mt-2 text-gray-600">Progress: Recording...</div>
        <div id="output-speech" class="mt-2 text-xl"></div>
      </div>
    </div>
  </div>

  <script>
    console.log('JavaScript running');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const audioCanvas = document.getElementById('audioCanvas');
    const audioCtx = audioCanvas.getContext('2d');
    const startSignBtn = document.getElementById('startSignBtn');
    const stopSignBtn = document.getElementById('stopSignBtn');
    const submitSignBtn = document.getElementById('submitSignBtn');
    const startSpeechBtn = document.getElementById('startSpeechBtn');
    const stopSpeechBtn = document.getElementById('stopSpeechBtn');
    const submitSpeechBtn = document.getElementById('submitSpeechBtn');
    const progressSignDiv = document.getElementById('progress-sign');
    const progressSpeechDiv = document.getElementById('progress-speech');
    const outputSign = document.getElementById('output-sign');
    const probabilitiesSign = document.getElementById('probabilities-sign');
    const outputSpeech = document.getElementById('output-speech');
    const createRoomBtn = document.getElementById('createRoomBtn');
    const joinRoomInput = document.getElementById('joinRoomInput');
    const joinRoomBtn = document.getElementById('joinRoomBtn');
    const currentRoomDiv = document.getElementById('currentRoom');
    const signSection = document.getElementById('signSection');
    const speechSection = document.getElementById('speechSection');
    const selectSignBtn = document.getElementById('selectSignBtn');
    const selectSpeechBtn = document.getElementById('selectSpeechBtn');
    let signFrames = [];
    let speechAudioData = [];
    let capturingSign = false;
    let recordingSpeech = false;
    let currentRoom = null;
    const NUM_SIGN_FRAMES = 100;
    let signFrameCount = 0;
    let socket = io();
    const API_URL = window.location.hostname === 'localhost' ? 'http://localhost:5000' : '';

    // Initialize MediaPipe Holistic
    const holistic = new Holistic({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/holistic/${file}`
    });
    holistic.setOptions({
      modelComplexity: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    // Toggle sections
    function showSection(section) {
      signSection.classList.add('hidden');
      speechSection.classList.add('hidden');
      if (section === 'sign') {
        signSection.classList.remove('hidden');
      } else if (section === 'speech') {
        speechSection.classList.remove('hidden');
      }
    }

    // Draw keypoints
    function drawLandmarks(results) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      if (results.poseLandmarks) {
        for (const landmark of results.poseLandmarks) {
          const x = landmark.x * canvas.width;
          const y = landmark.y * canvas.height;
          ctx.beginPath();
          ctx.arc(x, y, 3, 0, 2 * Math.PI);
          ctx.fillStyle = 'blue';
          ctx.fill();
        }
      }
      if (results.leftHandLandmarks) {
        for (const landmark of results.leftHandLandmarks) {
          const x = landmark.x * canvas.width;
          const y = landmark.y * canvas.height;
          ctx.beginPath();
          ctx.arc(x, y, 3, 0, 2 * Math.PI);
          ctx.fillStyle = 'red';
          ctx.fill();
        }
      }
      if (results.rightHandLandmarks) {
        for (const landmark of results.rightHandLandmarks) {
          const x = landmark.x * canvas.width;
          const y = landmark.y * canvas.height;
          ctx.beginPath();
          ctx.arc(x, y, 3, 0, 2 * Math.PI);
          ctx.fillStyle = 'green';
          ctx.fill();
        }
      }
    }

    // Extract keypoints
    function extractKeypoints(results) {
      const pose = new Array(33).fill(0).map(() => [0, 0, 0]);
      const leftHand = new Array(21).fill(0).map(() => [0, 0, 0]);
      const rightHand = new Array(21).fill(0).map(() => [0, 0, 0]);

      if (results.poseLandmarks) {
        results.poseLandmarks.forEach((landmark, i) => {
          pose[i] = [landmark.x, landmark.y, landmark.z];
        });
      }
      if (results.leftHandLandmarks) {
        results.leftHandLandmarks.forEach((landmark, i) => {
          leftHand[i] = [landmark.x, landmark.y, landmark.z];
        });
      }
      if (results.rightHandLandmarks) {
        results.rightHandLandmarks.forEach((landmark, i) => {
          rightHand[i] = [landmark.x, landmark.y, landmark.z];
        });
      }
      return [...pose, ...leftHand, ...rightHand.slice(0, 20)].flat();
    }

    // Start webcam
    async function startWebcam() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        const camera = new Camera(video, {
          onFrame: async () => {
            await holistic.send({ image: video });
          },
          width: 480,
          height: 360
        });
        await camera.start();
        console.log('MediaPipe camera started');
      } catch (err) {
        console.error('Failed to start webcam:', err);
        outputSign.textContent = 'Error: Unable to access camera - ' + err.message;
        alert('Please allow camera access to continue!');
      }
    }

    // Capture sign frames
    function captureSignFrame(results) {
      if (capturingSign && signFrames.length < NUM_SIGN_FRAMES && currentRoom) {
        const keypoints = extractKeypoints(results);
        signFrames.push(keypoints);
        signFrameCount++;
        const progress = Math.round((signFrameCount / NUM_SIGN_FRAMES) * 100);
        progressSignDiv.textContent = `Progress: ${progress}%`;
        console.log(`Captured sign frame ${signFrames.length}, keypoints: ${keypoints.length}`);

        if (signFrames.length < NUM_SIGN_FRAMES) {
          requestAnimationFrame(() => holistic.send({ image: video }));
        } else {
          stopSignRecording();
        }
      }
    }

    // Stop sign recording
    function stopSignRecording() {
      if (capturingSign) {
        capturingSign = false;
        signFrameCount = 0;
        startSignBtn.textContent = 'Start';
        stopSignBtn.classList.add('disabled');
        submitSignBtn.classList.remove('disabled');
        progressSignDiv.textContent = `Progress: 100%`;
        console.log(`Sign recording stopped, captured ${signFrames.length} frames`);
      }
    }

    // Submit sign translation
    async function predictSign() {
      if (!currentRoom) {
        outputSign.textContent = 'Error: Please join or create a room first';
        return;
      }
      try {
        submitSignBtn.classList.add('disabled');
        console.log('Sending sign to backend, frames:', signFrames.length, 'Room:', currentRoom);
        const response = await fetch(`${API_URL}/predict?room=${currentRoom}`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ frames: signFrames })
        });
        if (!response.ok) {
          throw new Error(`Backend error, status: ${response.status}`);
        }
        const result = await response.json();
        if (result.error) {
          outputSign.textContent = `Error: ${result.error}`;
        } else {
          outputSign.textContent = `Your Sign Result: ${result.gesture || 'Unknown'}`;
          probabilitiesSign.textContent = `Probs: ${result.probabilities ? result.probabilities.map((p, i) => `${i}: ${p.toFixed(4)}`).join(', ') : 'N/A'}`;
          socket.emit('translation_result', { gesture: result.gesture, probabilities: result.probabilities, type: 'sign' }, { room: currentRoom });
        }
        signFrames = [];
      } catch (err) {
        console.error('Sign prediction failed:', err);
        outputSign.textContent = `Error: Prediction failed - ${err.message}`;
        alert('Sign prediction failed, please try again.');
      } finally {
        submitSignBtn.classList.add('disabled');
        stopSignBtn.classList.add('disabled');
      }
    }

    // Handle MediaPipe results
    holistic.onResults((results) => {
      drawLandmarks(results);
      if (capturingSign) {
        captureSignFrame(results);
      }
    });

    // Audio recording setup
    let mediaRecorder;

    function startAudioRecording() {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          mediaRecorder = new MediaRecorder(stream);
          speechAudioData = [];
          mediaRecorder.ondataavailable = event => speechAudioData.push(event.data);
          mediaRecorder.onstop = () => {
            const audioBlob = new Blob(speechAudioData, { type: 'audio/webm' });
            stopSpeechRecording();
          };
          mediaRecorder.start();
          recordingSpeech = true;
          startSpeechBtn.textContent = 'Recording...';
          stopSpeechBtn.classList.remove('disabled');
          progressSpeechDiv.textContent = 'Progress: Recording...';
          console.log('Audio recording started');
        })
        .catch(err => {
          console.error('Failed to start audio recording:', err);
          outputSpeech.textContent = 'Error: Unable to access microphone - ' + err.message;
          alert('Please allow microphone access to continue!');
        });
    }

    function stopSpeechRecording() {
      if (recordingSpeech && mediaRecorder) {
        mediaRecorder.stop();
        recordingSpeech = false;
        startSpeechBtn.textContent = 'Start';
        stopSpeechBtn.classList.add('disabled');
        submitSpeechBtn.classList.remove('disabled');
        progressSpeechDiv.textContent = 'Progress: Recorded';
        console.log('Audio recording stopped');
      }
    }

    async function transcribeSpeech() {
      if (!currentRoom) {
        outputSpeech.textContent = 'Error: Please join or create a room first';
        return;
      }
      try {
        submitSpeechBtn.classList.add('disabled');
        const formData = new FormData();
        formData.append('audio', new Blob(speechAudioData, { type: 'audio/webm' }), 'audio.webm');
        console.log('Sending speech to backend, Room:', currentRoom);
        const response = await fetch(`${API_URL}/transcribe?room=${currentRoom}`, {
          method: 'POST',
          body: formData
        });
        if (!response.ok) {
          throw new Error(`Backend error, status: ${response.status}`);
        }
        const result = await response.json();
        if (result.error) {
          outputSpeech.textContent = `Error: ${result.error}`;
        } else {
          outputSpeech.textContent = `Your Speech Result: ${result.transcription || 'Unable to recognize speech'}`;
          socket.emit('translation_result', { gesture: result.transcription, probabilities: [], type: 'speech' }, { room: currentRoom });
        }
        speechAudioData = [];
      } catch (err) {
        console.error('Speech transcription failed:', err);
        outputSpeech.textContent = `Error: Transcription failed - ${err.message}`;
        alert('Speech transcription failed, please try again.');
      } finally {
        submitSpeechBtn.classList.add('disabled');
        stopSpeechBtn.classList.add('disabled');
      }
    }

    // Create room
    createRoomBtn.addEventListener('click', () => {
      currentRoom = 'room_' + Math.random().toString(36).substr(2, 9);
      socket.emit('join_room', { room: currentRoom });
      currentRoomDiv.textContent = `Current Room: ${currentRoom} (Share this ID with another user)`;
      console.log(`Created and joined room: ${currentRoom}`);
    });

    // Join room
    joinRoomBtn.addEventListener('click', () => {
      currentRoom = joinRoomInput.value || 'default_room';
      if (currentRoom) {
        socket.emit('join_room', { room: currentRoom });
        currentRoomDiv.textContent = `Current Room: ${currentRoom}`;
        console.log(`Joined room: ${currentRoom}`);
      } else {
        alert('Please enter a room ID');
      }
    });

    // Select mode
    selectSignBtn.addEventListener('click', () => {
      showSection('sign');
    });

    selectSpeechBtn.addEventListener('click', () => {
      showSection('speech');
    });

    // Receive translation result
    socket.on('translation_result', (data) => {
      if (data.type === 'sign') {
        outputSign.textContent = `Other's Sign Result: ${data.gesture || 'Unknown'}`;
        probabilitiesSign.textContent = `Other's Probs: ${data.probabilities ? data.probabilities.map((p, i) => `${i}: ${p.toFixed(4)}`).join(', ') : 'N/A'}`;
      } else if (data.type === 'speech') {
        outputSpeech.textContent = `Other's Speech Result: ${data.gesture || 'Unknown'}`;
      }
    });

    // Button events
    startSignBtn.addEventListener('click', () => {
      if (!capturingSign && currentRoom) {
        capturingSign = true;
        signFrames = [];
        startSignBtn.textContent = 'Recording...';
        stopSignBtn.classList.remove('disabled');
        submitSignBtn.classList.add('disabled');
        progressSignDiv.textContent = 'Progress: 0%';
        console.log('Sign recording started');
        holistic.send({ image: video });
      } else if (!currentRoom) {
        outputSign.textContent = 'Error: Please join or create a room first';
      }
    });

    stopSignBtn.addEventListener('click', stopSignRecording);
    submitSignBtn.addEventListener('click', predictSign);

    startSpeechBtn.addEventListener('click', startAudioRecording);
    stopSpeechBtn.addEventListener('click', stopSpeechRecording);
    submitSpeechBtn.addEventListener('click', transcribeSpeech);

    // Initialize
    showSection('sign'); // Default to sign translation
    startWebcam();
  </script>
</body>
</html>