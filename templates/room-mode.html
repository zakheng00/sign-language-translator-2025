<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Room Mode - Sign Language & Speech Translator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/holistic/holistic.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.socket.io/4.7.5/socket.io.min.js"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            primary: '#3B82F6',
            secondary: '#60A5FA'
          }
        }
      }
    }
  </script>
  <style>
    .hidden { display: none; }
    #video { border: 2px solid #000; transform: scaleX(-1); }
    #canvas { position: absolute; top: 100px; left: 50%; transform: translateX(-50%) scaleX(-1); }
    #audioCanvas { display: none; }
    .disabled { opacity: 0.5; pointer-events: none; }
    #chatBox { height: 200px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9; }
    .error { color: #dc2626; font-size: 0.875rem; }
    #signSection, #speechSection { position: relative; z-index: 0; }
    .controls { position: relative; z-index: 10; }
    .calibration-tip { color: #64748b; font-size: 0.875rem; margin-top: 5px; }
    .loading { animation: pulse 1.5s infinite; }
    @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.6; } 100% { opacity: 1; } }
  </style>
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
  <div class="max-w-4xl mx-auto p-6 space-y-8">
    <header class="text-center">
      <h1 class="text-4xl font-bold text-primary">Room Mode</h1>
      <p class="text-gray-500 mt-2">Create or join a room for real-time translation</p>
      <p class="calibration-tip">Please adjust your camera and place your hands in the center of the frame.</p>
    </header>

    <div class="space-y-4">
      <div class="flex justify-center space-x-4">
        <button id="selectSignBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Select Sign Translation</button>
        <button id="selectSpeechBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Select Speech Translation</button>
      </div>

      <div class="controls">
        <button id="createRoomBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Create Room</button>
        <div class="mt-2 flex items-center space-x-2">
          <input type="text" id="joinRoomInput" placeholder="Enter Room ID to Join" class="border p-2 rounded w-64">
          <button id="joinRoomBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary transition">Join Room</button>
        </div>
        <div id="currentRoom" class="mt-2 text-lg text-gray-700"></div>
        <div id="roomError" class="error hidden"></div>
        <div id="connectionStatus" class="mt-2 text-sm text-gray-600"></div>
      </div>

      <div id="signSection" class="section">
        <h2 class="text-2xl font-semibold text-primary mb-4">Sign Language Translation</h2>
        <div class="relative">
          <video id="video" width="480" height="360" autoplay></video>
          <canvas id="canvas" width="480" height="360"></canvas>
        </div>
        <br>
        <div class="controls">
          <button id="startSignBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary mt-2">Start</button>
          <button id="stopSignBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Stop</button>
          <button id="submitSignBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Translate</button>
        </div>
        <div id="progress-sign" class="mt-2 text-gray-600">Progress: 0%</div>
        <div id="output-sign" class="mt-2 text-xl"></div>
        <div id="probabilities-sign" class="mt-2 text-gray-600"></div>
      </div>

      <div id="speechSection" class="section hidden">
        <h2 class="text-2xl font-semibold text-primary mb-4">Speech Translation</h2>
        <canvas id="audioCanvas" width="480" height="100"></canvas>
        <br>
        <div class="controls">
          <button id="startSpeechBtn" class="bg-primary text-white px-6 py-3 rounded-lg hover:bg-secondary mt-2">Start</button>
          <button id="stopSpeechBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Stop</button>
          <button id="submitSpeechBtn" class="bg-gray-300 px-6 py-3 rounded-lg mt-2 disabled">Translate</button>
        </div>
        <div id="progress-speech" class="mt-2 text-gray-600">Progress: Recording...</div>
        <div id="output-speech" class="mt-2 text-xl"></div>
      </div>

      <div class="mt-6">
        <h2 class="text-2xl font-semibold text-primary mb-4">Chat History</h2>
        <div id="chatBox" class="bg-white rounded-lg shadow-md p-4"></div>
      </div>
    </div>
  </div>

  <script>
    console.log('JavaScript running');

    document.addEventListener('DOMContentLoaded', () => {
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const audioCanvas = document.getElementById('audioCanvas');
      const audioCtx = audioCanvas.getContext('2d');
      const startSignBtn = document.getElementById('startSignBtn');
      const stopSignBtn = document.getElementById('stopSignBtn');
      const submitSignBtn = document.getElementById('submitSignBtn');
      const startSpeechBtn = document.getElementById('startSpeechBtn');
      const stopSpeechBtn = document.getElementById('stopSpeechBtn');
      const submitSpeechBtn = document.getElementById('submitSpeechBtn');
      const progressSignDiv = document.getElementById('progress-sign');
      const progressSpeechDiv = document.getElementById('progress-speech');
      const outputSign = document.getElementById('output-sign');
      const probabilitiesSign = document.getElementById('probabilities-sign');
      const outputSpeech = document.getElementById('output-speech');
      const createRoomBtn = document.getElementById('createRoomBtn');
      const joinRoomInput = document.getElementById('joinRoomInput');
      const joinRoomBtn = document.getElementById('joinRoomBtn');
      const currentRoomDiv = document.getElementById('currentRoom');
      const roomError = document.getElementById('roomError');
      const connectionStatus = document.getElementById('connectionStatus');
      const chatBox = document.getElementById('chatBox');
      const signSection = document.getElementById('signSection');
      const speechSection = document.getElementById('speechSection');
      const selectSignBtn = document.getElementById('selectSignBtn');
      const selectSpeechBtn = document.getElementById('selectSpeechBtn');
      let signFrames = [];
      let speechAudioData = [];
      let capturingSign = false;
      let recordingSpeech = false;
      let currentRoom = null;
      const NUM_SIGN_FRAMES = 100;
      let signFrameCount = 0;
      const API_URL = window.location.hostname === 'localhost' ? 'http://localhost:5000' : 'https://sign-language-translator-2025.onrender.com';
      let socket = io(API_URL, { reconnection: true, reconnectionAttempts: 5, reconnectionDelay: 1000 });

      // Socket.IO 连接状态
      socket.on('connect', () => {
        connectionStatus.textContent = 'Connected to server';
        connectionStatus.classList.remove('loading');
        console.log('Connected to Socket.IO server with SID:', socket.id);
      });

      socket.on('connect_error', (error) => {
        connectionStatus.textContent = 'Connection error, retrying...';
        connectionStatus.classList.add('loading');
        console.error('Socket.IO connection error:', error);
      });

      socket.on('reconnect', () => {
        connectionStatus.textContent = 'Reconnected to server';
        connectionStatus.classList.remove('loading');
        if (currentRoom) socket.emit('join_room', { room_id: currentRoom });
      });

      socket.on('disconnect', () => {
        connectionStatus.textContent = 'Disconnected, attempting to reconnect...';
        connectionStatus.classList.add('loading');
      });

      // 显示错误
      function showError(message) {
        roomError.textContent = message;
        roomError.classList.remove('hidden');
        setTimeout(() => roomError.classList.add('hidden'), 5000);
      }

      // 添加消息到聊天框
      function addChatMessage(message, isSelf) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `mb-2 ${isSelf ? 'text-right' : 'text-left'}`;
        messageDiv.innerHTML = `<span class="inline-block p-2 rounded ${isSelf ? 'bg-primary text-white' : 'bg-gray-200'}">${message}</span>`;
        chatBox.appendChild(messageDiv);
        chatBox.scrollTop = chatBox.scrollHeight;
      }

      // 切换显示区域
      function showSection(section) {
        signSection.classList.add('hidden');
        speechSection.classList.add('hidden');
        if (section === 'sign') {
          signSection.classList.remove('hidden');
          console.log('Switched to Sign Translation');
        } else if (section === 'speech') {
          speechSection.classList.remove('hidden');
          console.log('Switched to Speech Translation');
        }
      }

      // 初始化 MediaPipe Holistic
      const holistic = new Holistic({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/holistic/${file}`
      });
      holistic.setOptions({
        modelComplexity: 1,
        minDetectionConfidence: 0.7,
        minTrackingConfidence: 0.7
      });

      // 绘制关键点
      function drawLandmarks(results) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        if (results.poseLandmarks) {
          for (const landmark of results.poseLandmarks) {
            const x = landmark.x * canvas.width;
            const y = landmark.y * canvas.height;
            ctx.beginPath();
            ctx.arc(x, y, 3, 0, 2 * Math.PI);
            ctx.fillStyle = 'blue';
            ctx.fill();
          }
        }
        if (results.leftHandLandmarks) {
          for (const landmark of results.leftHandLandmarks) {
            const x = landmark.x * canvas.width;
            const y = landmark.y * canvas.height;
            ctx.beginPath();
            ctx.arc(x, y, 3, 0, 2 * Math.PI);
            ctx.fillStyle = 'red';
            ctx.fill();
          }
        }
        if (results.rightHandLandmarks) {
          for (const landmark of results.rightHandLandmarks) {
            const x = landmark.x * canvas.width;
            const y = landmark.y * canvas.height;
            ctx.beginPath();
            ctx.arc(x, y, 3, 0, 2 * Math.PI);
            ctx.fillStyle = 'green';
            ctx.fill();
          }
        }
      }

      // 提取关键点
      function extractKeypoints(results) {
        const pose = new Array(33).fill(0).map(() => [0, 0, 0]);
        const leftHand = new Array(21).fill(0).map(() => [0, 0, 0]);
        const rightHand = new Array(21).fill(0).map(() => [0, 0, 0]);

        if (results.poseLandmarks) {
          results.poseLandmarks.forEach((landmark, i) => {
            pose[i] = [landmark.x, landmark.y, landmark.z];
          });
        }
        if (results.leftHandLandmarks) {
          results.leftHandLandmarks.forEach((landmark, i) => {
            leftHand[i] = [landmark.x, landmark.y, landmark.z];
          });
        }
        if (results.rightHandLandmarks) {
          results.rightHandLandmarks.forEach((landmark, i) => {
            rightHand[i] = [landmark.x, landmark.y, landmark.z];
          });
        }
        return [...pose, ...leftHand, ...rightHand.slice(0, 20)].flat();
      }

      // 启动摄像头
      async function startWebcam() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: true });
          video.srcObject = stream;
          const camera = new Camera(video, {
            onFrame: async () => {
              await holistic.send({ image: video });
            },
            width: 480,
            height: 360
          });
          await camera.start();
          console.log('MediaPipe camera started');
        } catch (err) {
          console.error('Failed to start webcam:', err);
          outputSign.textContent = 'Error: Unable to access camera - ' + err.message;
          alert('Please allow camera access to continue!');
        }
      }

      // 捕获手语帧
      function captureSignFrame(results) {
        if (capturingSign && signFrames.length < NUM_SIGN_FRAMES && currentRoom) {
          const keypoints = extractKeypoints(results);
          signFrames.push(keypoints);
          signFrameCount++;
          const progress = Math.round((signFrameCount / NUM_SIGN_FRAMES) * 100);
          progressSignDiv.textContent = `Progress: ${progress}%`;
          console.log(`Captured sign frame ${signFrames.length}, keypoints: ${keypoints.length}`);

          if (signFrames.length < NUM_SIGN_FRAMES) {
            requestAnimationFrame(() => holistic.send({ image: video }));
          } else {
            stopSignRecording();
          }
        }
      }

      // 停止手语录制
      function stopSignRecording() {
        if (capturingSign) {
          capturingSign = false;
          signFrameCount = 0;
          startSignBtn.textContent = 'Start';
          stopSignBtn.classList.add('disabled');
          submitSignBtn.classList.remove('disabled');
          progressSignDiv.textContent = `Progress: 100%`;
          console.log(`Sign recording stopped, captured ${signFrames.length} frames`);
        }
      }

      // 提交手语翻译
      async function predictSign() {
        if (!currentRoom) {
          outputSign.textContent = 'Error: Please join or create a room first';
          return;
        }
        try {
          submitSignBtn.classList.add('disabled');
          progressSignDiv.textContent = 'Progress: Translating...';
          console.log('Sending sign to backend, frames:', signFrames.length, 'Room:', currentRoom);
          const response = await fetch(`${API_URL}/predict`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json', 'X-Socket-ID': socket.id },
            body: JSON.stringify({ frames: signFrames })
          });
          if (!response.ok) throw new Error(`Backend error, status: ${response.status}`);
          const result = await response.json();
          if (result.error) {
            outputSign.textContent = `Error: ${result.error}`;
          } else {
            const message = result.gesture || 'Unknown';
            outputSign.textContent = `Your Sign Result: ${message}`;
            probabilitiesSign.textContent = `Probs: ${result.probabilities ? result.probabilities.map((p, i) => `${i}: ${p.toFixed(4)}`).join(', ') : 'N/A'}`;
            addChatMessage(message, true);
            socket.emit('send_gesture', { room_id: currentRoom, user_id: socket.id, gesture: message });
          }
          signFrames = [];
        } catch (err) {
          console.error('Sign prediction failed:', err);
          outputSign.textContent = `Error: Prediction failed - ${err.message}`;
          alert('Sign prediction failed, please try again.');
        } finally {
          submitSignBtn.classList.add('disabled');
          stopSignBtn.classList.add('disabled');
          progressSignDiv.textContent = 'Progress: 0%';
        }
      }

      // 处理 MediaPipe 结果
      holistic.onResults((results) => {
        drawLandmarks(results);
        if (capturingSign) captureSignFrame(results);
      });

      // 音频录制设置
      let mediaRecorder;

      function startAudioRecording() {
        if (!currentRoom) {
          outputSpeech.textContent = 'Error: Please join or create a room first';
          return;
        }
        navigator.mediaDevices.getUserMedia({ audio: true })
          .then(stream => {
            mediaRecorder = new MediaRecorder(stream);
            speechAudioData = [];
            mediaRecorder.ondataavailable = event => speechAudioData.push(event.data);
            mediaRecorder.onstop = () => stopSpeechRecording();
            mediaRecorder.start();
            recordingSpeech = true;
            startSpeechBtn.textContent = 'Recording...';
            stopSpeechBtn.classList.remove('disabled');
            progressSpeechDiv.textContent = 'Progress: Recording...';
            console.log('Audio recording started');
          })
          .catch(err => {
            console.error('Failed to start audio recording:', err);
            outputSpeech.textContent = 'Error: Unable to access microphone - ' + err.message;
            alert('Please allow microphone access to continue!');
          });
      }

      function stopSpeechRecording() {
        if (recordingSpeech && mediaRecorder) {
          mediaRecorder.stop();
          recordingSpeech = false;
          startSpeechBtn.textContent = 'Start';
          stopSpeechBtn.classList.add('disabled');
          submitSpeechBtn.classList.remove('disabled');
          progressSpeechDiv.textContent = 'Progress: Recorded';
          console.log('Audio recording stopped');
        }
      }

      async function transcribeSpeech() {
        if (!currentRoom) {
          outputSpeech.textContent = 'Error: Please join or create a room first';
          return;
        }
        try {
          submitSpeechBtn.classList.add('disabled');
          progressSpeechDiv.textContent = 'Progress: Translating...';
          const formData = new FormData();
          formData.append('audio', new Blob(speechAudioData, { type: 'audio/webm' }), 'audio.webm');
          console.log('Sending speech to backend, Room:', currentRoom);
          const response = await fetch(`${API_URL}/transcribe`, {
            method: 'POST',
            body: formData,
            headers: { 'X-Socket-ID': socket.id }
          });
          if (!response.ok) throw new Error(`Backend error, status: ${response.status}`);
          const result = await response.json();
          if (result.error) {
            outputSpeech.textContent = `Error: ${result.error}`;
          } else {
            const message = result.transcription || 'Unable to recognize speech';
            outputSpeech.textContent = `Your Speech Result: ${message}`;
            addChatMessage(message, true);
            socket.emit('send_transcription', { room_id: currentRoom, user_id: socket.id, text: message });
          }
          speechAudioData = [];
        } catch (err) {
          console.error('Speech transcription failed:', err);
          outputSpeech.textContent = `Error: Transcription failed - ${err.message}`;
          alert('Speech transcription failed, please try again.');
        } finally {
          submitSpeechBtn.classList.add('disabled');
          stopSpeechBtn.classList.add('disabled');
          progressSpeechDiv.textContent = 'Progress: 0%';
        }
      }

      // 创建房间
      createRoomBtn.addEventListener('click', () => {
        currentRoom = 'room_' + Math.random().toString(36).substr(2, 9);
        socket.emit('join_room', { room_id: currentRoom });
        currentRoomDiv.textContent = `Current Room: ${currentRoom} (Share this ID with another user)`;
        console.log(`Created and joined room: ${currentRoom}`);
        roomError.classList.add('hidden');
      });

      // 加入房间
      joinRoomBtn.addEventListener('click', () => {
        const roomId = joinRoomInput.value.trim();
        if (roomId) {
          currentRoom = roomId;
          socket.emit('join_room', { room_id: currentRoom });
          currentRoomDiv.textContent = `Current Room: ${currentRoom} (Connecting...)`;
          console.log(`Joined room: ${currentRoom}`);
          roomError.classList.add('hidden');
        } else {
          showError('Please enter a valid room ID');
        }
      });

      // 接收加入确认和翻译结果
      socket.on('user_joined', (data) => {
        console.log(`User ${data.user_id} joined room ${data.room_id}`);
        addChatMessage(`User ${data.user_id} joined`, false);
      });

      socket.on('transcription', (data) => {
        if (data.user_id !== socket.id) {
          outputSpeech.textContent = `Other's Speech Result: ${data.text}`;
          addChatMessage(data.text, false);
        }
      });

      socket.on('gesture', (data) => {
        if (data.user_id !== socket.id) {
          outputSign.textContent = `Other's Sign Result: ${data.gesture}`;
          probabilitiesSign.textContent = `Other's Probs: ${data.probabilities ? data.probabilities.map((p, i) => `${i}: ${p.toFixed(4)}`).join(', ') : 'N/A'}`;
          addChatMessage(data.gesture, false);
        }
      });

      // 按钮事件
      selectSignBtn.addEventListener('click', () => showSection('sign'));
      selectSpeechBtn.addEventListener('click', () => showSection('speech'));

      startSignBtn.addEventListener('click', () => {
        if (!capturingSign && currentRoom) {
          capturingSign = true;
          signFrames = [];
          startSignBtn.textContent = 'Recording...';
          stopSignBtn.classList.remove('disabled');
          submitSignBtn.classList.add('disabled');
          progressSignDiv.textContent = 'Progress: 0%';
          console.log('Sign recording started');
          holistic.send({ image: video });
        } else if (!currentRoom) {
          outputSign.textContent = 'Error: Please join or create a room first';
        }
      });

      stopSignBtn.addEventListener('click', stopSignRecording);
      submitSignBtn.addEventListener('click', predictSign);

      startSpeechBtn.addEventListener('click', startAudioRecording);
      stopSpeechBtn.addEventListener('click', stopSpeechRecording);
      submitSpeechBtn.addEventListener('click', transcribeSpeech);

      // 初始化
      showSection('sign');
      startWebcam();
    });
  </script>
</body>
</html>